{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta notebook contiene bloques de código útiles para realizar Q-learning en el entorno \"Descent Env\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from descent_env import DescentEnv\n",
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading config from C:\\Users\\npere\\bluesky\\settings.cfg\n",
      "Reading magnetic variation data\n",
      "Loading global navigation database...\n",
      "Reading cache: C:\\Users\\npere\\bluesky\\cache\\navdata.p\n",
      "Successfully loaded OpenAP performance model\n",
      "Failed to load BADA performance model\n",
      "Successfully loaded legacy performance model\n",
      "Successfully loaded plugin AREA\n",
      "Successfully loaded plugin DATAFEED\n"
     ]
    }
   ],
   "source": [
    "# Cambiar render_mode a rgb_array para entrenar/testear\n",
    "env = DescentEnv(render_mode='human')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict('altitude': Box(-inf, inf, (1,), float64), 'runway_distance': Box(-inf, inf, (1,), float64), 'target_altitude': Box(-inf, inf, (1,), float64), 'vz': Box(-inf, inf, (1,), float64))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Action Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(-1.0, 1.0, (1,), float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discretización de los estados\n",
    "\n",
    "**Nota:** es importante que chequeen el espacio de observación y el espacio de acción del entorno. Los números usados son ejemplos y pueden no ser correctos\n",
    "\n",
    "**Discretizacion actualizada**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.05263158, 0.10526316, 0.15789474, 0.21052632,\n",
       "       0.26315789, 0.31578947, 0.36842105, 0.42105263, 0.47368421,\n",
       "       0.52631579, 0.57894737, 0.63157895, 0.68421053, 0.73684211,\n",
       "       0.78947368, 0.84210526, 0.89473684, 0.94736842, 1.        ])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ALT_MIN = 2000\n",
    "ALT_MAX = 4000\n",
    "ALT_MEAN = 1500\n",
    "ALT_STD = 3000\n",
    "VZ_MEAN = 0\n",
    "VZ_STD = 5\n",
    "RWY_DIS_MEAN = 100\n",
    "RWY_DIS_STD = 200\n",
    "altitude_space = np.linspace(0, 1, 20)\n",
    "vertical_velocity_space = np.linspace(-10, 10, 20) \n",
    "target_altitude_space = np.linspace(0, 1, 20)\n",
    "runway_distance_space = np.linspace(0, 0.5, 5)\n",
    "altitude_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtener el estado a partir de la observación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state(obs):\n",
    "    alt = obs['altitude'][0]\n",
    "    vz = obs['vz'][0]\n",
    "    target_alt = obs['target_altitude'][0]\n",
    "    runway_dist = obs['runway_distance'][0]\n",
    "    alt_idx = np.clip(np.digitize(alt, altitude_space) - 1, 0, len(altitude_space) - 1)\n",
    "    vz_idx = np.clip(np.digitize(vz, vertical_velocity_space) - 1, 0, len(vertical_velocity_space) - 1)\n",
    "    target_alt_idx = np.clip(np.digitize(target_alt, target_altitude_space) - 1, 0, len(target_altitude_space) - 1)\n",
    "    runway_dist_idx = np.clip(np.digitize(runway_dist, runway_distance_space) - 1, 0, len(runway_distance_space) - 1)\n",
    "    return alt_idx, vz_idx, target_alt_idx, runway_dist_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('altitude', array([-0.99177144])), ('runway_distance', array([-0.97990949])), ('target_altitude', array([0.39019795])), ('vz', array([-0.73939261]))])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-1, 45, 33, -1)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = env.observation_space.sample()\n",
    "print(obs)\n",
    "state = get_state(obs) # Ejemplo de obs\n",
    "state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discretización de las acciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1.0,\n",
       " -0.7777777777777778,\n",
       " -0.5555555555555556,\n",
       " -0.33333333333333337,\n",
       " -0.11111111111111116,\n",
       " 0.11111111111111116,\n",
       " 0.33333333333333326,\n",
       " 0.5555555555555554,\n",
       " 0.7777777777777777,\n",
       " 1.0]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = list(np.linspace(-1, 1, 10))\n",
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_action():\n",
    "    return random.choice(actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicilización de la tabla Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 20, 20, 10, 10)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q = np.zeros((len(altitude_space), len(vertical_velocity_space), len(target_altitude_space), len(runway_distance_space), len(actions)))\n",
    "Q.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtención de la acción a partir de la tabla Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_policy(state, Q):\n",
    "    action = actions[np.argmax(Q[state])]\n",
    "    return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epsilon-Greedy Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy_policy(state, Q, epsilon=0.1):\n",
    "    explore = np.random.binomial(1, epsilon)\n",
    "    if explore:\n",
    "        action = get_sample_action()\n",
    "    else:\n",
    "        action = optimal_policy(state, Q)\n",
    "        \n",
    "    return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo de episodio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'altitude': array([0.28284088]), 'vz': array([0.27777778]), 'target_altitude': array([0.38833333]), 'runway_distance': array([0.37619696])}\n",
      "total_reward -82423.0027900281\n",
      "steps 10000\n",
      "min_runway_distance: -0.5212062905283475\n",
      "max_runway_distance: 0.47556561005149406\n"
     ]
    }
   ],
   "source": [
    "obs, _ = env.reset()\n",
    "print(obs)\n",
    "done = False\n",
    "total_reward = 0\n",
    "state = get_state(obs)\n",
    "steps = 0\n",
    "\n",
    "min_runway_distance = float('inf')\n",
    "max_runway_distance = float('-inf')\n",
    "\n",
    "for _ in range(10000):\n",
    "    # Acción del modelo\n",
    "    action = epsilon_greedy_policy(state, Q, 0.5)\n",
    "    action_idx = actions.index(action)\n",
    "    real_action = np.array([action])\n",
    "    obs, reward, done, _, _ = env.step(real_action)\n",
    "    next_state = get_state(obs)\n",
    "    \n",
    "    # Guardar min y max runway_distance\n",
    "    runway_distance = obs['runway_distance'][0]\n",
    "    if runway_distance < min_runway_distance:\n",
    "        min_runway_distance = runway_distance\n",
    "    if runway_distance > max_runway_distance:\n",
    "        max_runway_distance = runway_distance\n",
    "\n",
    "    state = next_state\n",
    "    total_reward += reward\n",
    "    steps += 1\n",
    "    if done:\n",
    "        obs, _ = env.reset()\n",
    "        state = get_state(obs)\n",
    "        done = False\n",
    "\n",
    "env.close()\n",
    "print('total_reward', total_reward)\n",
    "print('steps', steps)\n",
    "print('min_runway_distance:', min_runway_distance)\n",
    "print('max_runway_distance:', max_runway_distance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Media de reward en episodios 1 a 100: -136.56073725871664\n",
      "Media de reward en episodios 101 a 200: -149.58193995688336\n",
      "Media de reward en episodios 201 a 300: -133.09370022045002\n",
      "Media de reward en episodios 301 a 400: -113.33480838853335\n",
      "Media de reward en episodios 401 a 500: -107.54088717288332\n",
      "Media de reward en episodios 501 a 600: -107.28128508871667\n",
      "Media de reward en episodios 601 a 700: -99.75968446674999\n",
      "Media de reward en episodios 701 a 800: -100.02867843245002\n",
      "Media de reward en episodios 801 a 900: -96.81750500571665\n",
      "Media de reward en episodios 901 a 1000: -95.64718879928336\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "total_reward = 0\n",
    "rewards = []\n",
    "max_steps = 1\n",
    "\n",
    "obs, _ = env.reset()\n",
    "done = False\n",
    "\n",
    "while i < 1000:\n",
    "    obs, _ = env.reset()\n",
    "    done = False\n",
    "    episode_reward = 0\n",
    "    while not done:\n",
    "        p = random.uniform(0, 1)\n",
    "        state = get_state(obs)\n",
    "        if p < 0.3:\n",
    "            action = get_sample_action()\n",
    "        else:\n",
    "            action = optimal_policy(state, Q)\n",
    "        next_obs, reward, done, _, _ = env.step(np.array([action]))\n",
    "        next_state = get_state(next_obs)\n",
    "        action_idx = actions.index(action)\n",
    "        Q[state][action_idx] = Q[state][action_idx] + 0.9 * (reward + 0.9 * np.max(Q[next_state]) - Q[state][action_idx])\n",
    "        obs = next_obs\n",
    "        episode_reward += reward\n",
    "    rewards.append(episode_reward)\n",
    "    if (i + 1) % 100 == 0:\n",
    "        mean_reward = np.mean(rewards[-100:])\n",
    "        print(f\"Media de reward en episodios {i-98} a {i+1}: {mean_reward}\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading config from C:\\Users\\npere\\bluesky\\settings.cfg\n",
      "Reading magnetic variation data\n",
      "Loading global navigation database...\n",
      "Reading cache: C:\\Users\\npere\\bluesky\\cache\\navdata.p\n",
      "Attempt to reimplement AREA from <bound method Area.set_area of <bluesky.plugins.area.Area object at 0x0000028E21095E40>> to <bound method Area.set_area of <bluesky.plugins.area.Area object at 0x0000028E21095E40>>\n",
      "Attempt to reimplement EXP from <function init_plugin.<locals>.<lambda> at 0x0000028E21005630> to <function init_plugin.<locals>.<lambda> at 0x0000028E45E94820>\n",
      "Attempt to reimplement TAXI from <bound method Area.set_taxi of <bluesky.plugins.area.Area object at 0x0000028E21095E40>> to <bound method Area.set_taxi of <bluesky.plugins.area.Area object at 0x0000028E21095E40>>\n",
      "Successfully loaded plugin AREA\n",
      "Attempt to reimplement DATAFEED from <bound method Modesbeast.toggle of <bluesky.plugins.adsbfeed.Modesbeast object at 0x0000028E21097790>> to <bound method Modesbeast.toggle of <bluesky.plugins.adsbfeed.Modesbeast object at 0x0000028E3AA74070>>\n",
      "Successfully loaded plugin DATAFEED\n",
      "Attempt to reimplement PLUGINS from <function init.<locals>.manage at 0x0000028E21099360> to <function init.<locals>.manage at 0x0000028E45E955A0>\n",
      "Attempt to reimplement ADDNODES from <bound method Node.addnodes of <bluesky.network.detached.Node object at 0x0000028E20FF2350>> to <bound method Node.addnodes of <bluesky.network.detached.Node object at 0x0000028E3AB1E110>>\n",
      "Attempt to reimplement AIRWAY from <bound method Traffic.airwaycmd of <bluesky.traffic.traffic.Traffic object at 0x0000028E1C975030>> to <bound method Traffic.airwaycmd of <bluesky.traffic.traffic.Traffic object at 0x0000028E1C975030>>\n",
      "Attempt to reimplement ATALT from <bound method Condition.ataltcmd of <bluesky.traffic.conditional.Condition object at 0x0000028E20FF2DD0>> to <bound method Condition.ataltcmd of <bluesky.traffic.conditional.Condition object at 0x0000028E20FF2DD0>>\n",
      "Attempt to reimplement ATDIST from <bound method Condition.atdistcmd of <bluesky.traffic.conditional.Condition object at 0x0000028E20FF2DD0>> to <bound method Condition.atdistcmd of <bluesky.traffic.conditional.Condition object at 0x0000028E20FF2DD0>>\n",
      "Attempt to reimplement ATSPD from <bound method Condition.atspdcmd of <bluesky.traffic.conditional.Condition object at 0x0000028E20FF2DD0>> to <bound method Condition.atspdcmd of <bluesky.traffic.conditional.Condition object at 0x0000028E20FF2DD0>>\n",
      "Attempt to reimplement BANK from <bound method Traffic.setbanklim of <bluesky.traffic.traffic.Traffic object at 0x0000028E1C975030>> to <bound method Traffic.setbanklim of <bluesky.traffic.traffic.Traffic object at 0x0000028E1C975030>>\n",
      "Attempt to reimplement BATCH from <bound method Simulation.batch of <bluesky.simulation.simulation.Simulation object at 0x0000028E1C9744F0>> to <bound method Simulation.batch of <bluesky.simulation.simulation.Simulation object at 0x0000028E3AB1C160>>\n",
      "Attempt to reimplement BLUESKY from <function singbluesky at 0x0000028E1C938940> to <function singbluesky at 0x0000028E1C938940>\n",
      "Attempt to reimplement BENCHMARK from <bound method Simulation.benchmark of <bluesky.simulation.simulation.Simulation object at 0x0000028E1C9744F0>> to <bound method Simulation.benchmark of <bluesky.simulation.simulation.Simulation object at 0x0000028E3AB1C160>>\n",
      "Attempt to reimplement BOX from <function initbasecmds.<locals>.<lambda> at 0x0000028E21039240> to <function initbasecmds.<locals>.<lambda> at 0x0000028E45E955A0>\n",
      "Attempt to reimplement CALC from <function calculator at 0x0000028E1C9388B0> to <function calculator at 0x0000028E1C9388B0>\n",
      "Attempt to reimplement CASMACHTHR from <function casmachthr at 0x0000028E1C8E0C10> to <function casmachthr at 0x0000028E1C8E0C10>\n",
      "Attempt to reimplement CD from <function setscenpath at 0x0000028E1C938A60> to <function setscenpath at 0x0000028E1C938A60>\n",
      "Attempt to reimplement CIRCLE from <function initbasecmds.<locals>.<lambda> at 0x0000028E210993F0> to <function initbasecmds.<locals>.<lambda> at 0x0000028E45E94940>\n",
      "Attempt to reimplement CLRCRECMD from <bound method Traffic.clrcrecmd of <bluesky.traffic.traffic.Traffic object at 0x0000028E1C975030>> to <bound method Traffic.clrcrecmd of <bluesky.traffic.traffic.Traffic object at 0x0000028E1C975030>>\n",
      "Attempt to reimplement CRE from <bound method Traffic.cre of <bluesky.traffic.traffic.Traffic object at 0x0000028E1C975030>> to <bound method Traffic.cre of <bluesky.traffic.traffic.Traffic object at 0x0000028E1C975030>>\n",
      "Attempt to reimplement CRECMD from <bound method Traffic.crecmd of <bluesky.traffic.traffic.Traffic object at 0x0000028E1C975030>> to <bound method Traffic.crecmd of <bluesky.traffic.traffic.Traffic object at 0x0000028E1C975030>>\n",
      "Attempt to reimplement CRECONFS from <bound method Traffic.creconfs of <bluesky.traffic.traffic.Traffic object at 0x0000028E1C975030>> to <bound method Traffic.creconfs of <bluesky.traffic.traffic.Traffic object at 0x0000028E1C975030>>\n",
      "Attempt to reimplement DATE from <bound method Simulation.setutc of <bluesky.simulation.simulation.Simulation object at 0x0000028E1C9744F0>> to <bound method Simulation.setutc of <bluesky.simulation.simulation.Simulation object at 0x0000028E3AB1C160>>\n",
      "Attempt to reimplement DEFWPT from <bound method Navdatabase.defwpt of <bluesky.navdatabase.navdatabase.Navdatabase object at 0x0000028E1C974520>> to <bound method Navdatabase.defwpt of <bluesky.navdatabase.navdatabase.Navdatabase object at 0x0000028E210B3760>>\n",
      "Attempt to reimplement DEL from <function initbasecmds.<locals>.<lambda> at 0x0000028E21099870> to <function initbasecmds.<locals>.<lambda> at 0x0000028E45E94DC0>\n",
      "Attempt to reimplement DIST from <function distcalc at 0x0000028E1C9389D0> to <function distcalc at 0x0000028E1C9389D0>\n",
      "Attempt to reimplement DOC from <bound method ScreenIO.show_cmd_doc of <bluesky.simulation.screenio.ScreenIO object at 0x0000028E20FF10F0>> to <bound method ScreenIO.show_cmd_doc of <bluesky.simulation.screenio.ScreenIO object at 0x0000028E20FF10F0>>\n",
      "Attempt to reimplement DT from <function initbasecmds.<locals>.<lambda> at 0x0000028E21099900> to <function initbasecmds.<locals>.<lambda> at 0x0000028E45E94670>\n",
      "Attempt to reimplement DTMULT from <bound method Simulation.set_dtmult of <bluesky.simulation.simulation.Simulation object at 0x0000028E1C9744F0>> to <bound method Simulation.set_dtmult of <bluesky.simulation.simulation.Simulation object at 0x0000028E3AB1C160>>\n",
      "Attempt to reimplement ECHO from <function initbasecmds.<locals>.<lambda> at 0x0000028E21099990> to <function initbasecmds.<locals>.<lambda> at 0x0000028E45E94A60>\n",
      "Attempt to reimplement FF from <bound method Simulation.fastforward of <bluesky.simulation.simulation.Simulation object at 0x0000028E1C9744F0>> to <bound method Simulation.fastforward of <bluesky.simulation.simulation.Simulation object at 0x0000028E3AB1C160>>\n",
      "Attempt to reimplement FIXDT from <function initbasecmds.<locals>.<lambda> at 0x0000028E21099A20> to <function initbasecmds.<locals>.<lambda> at 0x0000028E45E94AF0>\n",
      "Attempt to reimplement GROUP from <bound method TrafficGroups.group of <bluesky.traffic.trafficgroups.TrafficGroups object at 0x0000028E20FCAA10>> to <bound method TrafficGroups.group of <bluesky.traffic.trafficgroups.TrafficGroups object at 0x0000028E20FCAA10>>\n",
      "Attempt to reimplement HOLD from <bound method Simulation.hold of <bluesky.simulation.simulation.Simulation object at 0x0000028E1C9744F0>> to <bound method Simulation.hold of <bluesky.simulation.simulation.Simulation object at 0x0000028E3AB1C160>>\n",
      "Attempt to reimplement IMPLEMENTATION from <function select_implementation at 0x0000028E1C889240> to <function select_implementation at 0x0000028E1C889240>\n",
      "Attempt to reimplement INSEDIT from <bound method ScreenIO.cmdline of <bluesky.simulation.screenio.ScreenIO object at 0x0000028E20FF10F0>> to <bound method ScreenIO.cmdline of <bluesky.simulation.screenio.ScreenIO object at 0x0000028E20FF10F0>>\n",
      "Attempt to reimplement LEGEND from <function initbasecmds.<locals>.<lambda> at 0x0000028E21099AB0> to <function initbasecmds.<locals>.<lambda> at 0x0000028E45E94CA0>\n",
      "Attempt to reimplement LINE from <function initbasecmds.<locals>.<lambda> at 0x0000028E21099B40> to <function initbasecmds.<locals>.<lambda> at 0x0000028E45E94C10>\n",
      "Attempt to reimplement LSVAR from <function lsvar at 0x0000028E1C8B8D30> to <function lsvar at 0x0000028E1C8B8D30>\n",
      "Attempt to reimplement MAGVAR from <function magdeccmd at 0x0000028E1C8E2B90> to <function magdeccmd at 0x0000028E1C8E2B90>\n",
      "Attempt to reimplement MCRE from <bound method Traffic.mcre of <bluesky.traffic.traffic.Traffic object at 0x0000028E1C975030>> to <bound method Traffic.mcre of <bluesky.traffic.traffic.Traffic object at 0x0000028E1C975030>>\n",
      "Attempt to reimplement MOVE from <bound method Traffic.move of <bluesky.traffic.traffic.Traffic object at 0x0000028E1C975030>> to <bound method Traffic.move of <bluesky.traffic.traffic.Traffic object at 0x0000028E1C975030>>\n",
      "Attempt to reimplement NOISE from <bound method Traffic.setnoise of <bluesky.traffic.traffic.Traffic object at 0x0000028E1C975030>> to <bound method Traffic.setnoise of <bluesky.traffic.traffic.Traffic object at 0x0000028E1C975030>>\n",
      "Attempt to reimplement OP from <bound method Simulation.op of <bluesky.simulation.simulation.Simulation object at 0x0000028E1C9744F0>> to <bound method Simulation.op of <bluesky.simulation.simulation.Simulation object at 0x0000028E3AB1C160>>\n",
      "Attempt to reimplement PLOT from <function plot at 0x0000028E1C913400> to <function plot at 0x0000028E1C913400>\n",
      "Attempt to reimplement POLY from <function initbasecmds.<locals>.<lambda> at 0x0000028E21099BD0> to <function initbasecmds.<locals>.<lambda> at 0x0000028E45E94310>\n",
      "Attempt to reimplement POLYALT from <function initbasecmds.<locals>.<lambda> at 0x0000028E21099C60> to <function initbasecmds.<locals>.<lambda> at 0x0000028E45E95000>\n",
      "Attempt to reimplement POLYLINE from <function initbasecmds.<locals>.<lambda> at 0x0000028E21099CF0> to <function initbasecmds.<locals>.<lambda> at 0x0000028E45E956C0>\n",
      "Attempt to reimplement POS from <bound method Traffic.poscommand of <bluesky.traffic.traffic.Traffic object at 0x0000028E1C975030>> to <bound method Traffic.poscommand of <bluesky.traffic.traffic.Traffic object at 0x0000028E1C975030>>\n",
      "Attempt to reimplement REALTIME from <bound method Simulation.realtime of <bluesky.simulation.simulation.Simulation object at 0x0000028E1C9744F0>> to <bound method Simulation.realtime of <bluesky.simulation.simulation.Simulation object at 0x0000028E3AB1C160>>\n",
      "Attempt to reimplement RESET from <bound method Simulation.reset of <bluesky.simulation.simulation.Simulation object at 0x0000028E1C9744F0>> to <bound method Simulation.reset of <bluesky.simulation.simulation.Simulation object at 0x0000028E3AB1C160>>\n",
      "Attempt to reimplement SEED from <function Simulation.setseed at 0x0000028E1C93ACB0> to <function Simulation.setseed at 0x0000028E1C93ACB0>\n",
      "Attempt to reimplement THR from <bound method Traffic.setthrottle of <bluesky.traffic.traffic.Traffic object at 0x0000028E1C975030>> to <bound method Traffic.setthrottle of <bluesky.traffic.traffic.Traffic object at 0x0000028E1C975030>>\n",
      "Attempt to reimplement TIME from <bound method Simulation.setutc of <bluesky.simulation.simulation.Simulation object at 0x0000028E1C9744F0>> to <bound method Simulation.setutc of <bluesky.simulation.simulation.Simulation object at 0x0000028E3AB1C160>>\n",
      "Attempt to reimplement TRAIL from <bound method Trails.setTrails of <bluesky.traffic.trails.Trails object at 0x0000028E1C9749A0>> to <bound method Trails.setTrails of <bluesky.traffic.trails.Trails object at 0x0000028E1C9749A0>>\n",
      "Attempt to reimplement UNGROUP from <bound method TrafficGroups.ungroup of <bluesky.traffic.trafficgroups.TrafficGroups object at 0x0000028E20FCAA10>> to <bound method TrafficGroups.ungroup of <bluesky.traffic.trafficgroups.TrafficGroups object at 0x0000028E20FCAA10>>\n",
      "Total reward (Q final): -54.44555459166666\n",
      "Steps: 41\n"
     ]
    }
   ],
   "source": [
    "env = DescentEnv(render_mode='human')     \n",
    "obs, _ = env.reset()\n",
    "done = False\n",
    "total_reward = 0\n",
    "steps = 0\n",
    "\n",
    "while not done:\n",
    "    state = get_state(obs)\n",
    "    action = optimal_policy(state, Q)\n",
    "    obs, reward, done, _, _ = env.step(np.array([action]))\n",
    "    total_reward += reward\n",
    "    steps += 1\n",
    "    env.render()\n",
    "\n",
    "env.close()\n",
    "print(f\"Total reward (Q final): {total_reward}\")\n",
    "print(f\"Steps: {steps}\")   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
